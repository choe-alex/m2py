{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['100C_15min_Sub4_Dev2_seg1.npy', '100C_15min_Sub4_Dev2_seg2.npy', '100C_15min_Sub4_Dev4_seg1.npy', '100C_15min_Sub4_Dev4_seg2.npy', '100C_15min_Sub4_Dev7_seg1.npy', '100C_15min_Sub4_Dev7_seg2.npy', '100C_30min_Sub7_Dev2_seg1.npy', '100C_30min_Sub7_Dev2_seg2.npy', '100C_30min_Sub7_Dev4_seg1.npy', '100C_30min_Sub7_Dev4_seg2.npy', '100C_30min_Sub7_Dev7_seg1.npy', '100C_30min_Sub7_Dev7_seg2.npy', '100C_5min_Sub1_Dev3_seg1.npy', '100C_5min_Sub1_Dev3_seg2.npy', '100C_5min_Sub1_Dev4_90D_seg1.npy', '100C_5min_Sub1_Dev4_90D_seg2.npy', '100C_5min_Sub1_Dev4_seg1.npy', '100C_5min_Sub1_Dev4_seg2.npy', '125C_15min_Sub4_Dev1_seg1.npy', '125C_15min_Sub4_Dev1_seg2.npy', '125C_15min_Sub4_Dev2_seg1.npy', '125C_15min_Sub4_Dev2_seg2.npy', '125C_15min_Sub4_Dev6_seg1.npy', '125C_15min_Sub4_Dev6_seg2.npy', '125C_15min_Sub4_Dev7_seg1.npy', '125C_15min_Sub4_Dev7_seg2.npy', '125C_15min_Sub4_postexam_seg1.npy', '125C_15min_Sub4_postexam_seg2.npy', '125C_30min_Sub8_Dev3_seg1.npy', '125C_30min_Sub8_Dev3_seg2.npy', '125C_30min_Sub8_postexam_seg1.npy', '125C_30min_Sub8_postexam_seg2.npy', '125C_5min_Sub1_Dev2_seg1.npy', '125C_5min_Sub1_Dev2_seg2.npy', '125C_5min_Sub1_Dev3_seg1.npy', '125C_5min_Sub1_Dev3_seg2.npy', '125C_5min_Sub1_Dev6_seg1.npy', '125C_5min_Sub1_Dev6_seg2.npy', '125C_5min_Sub1_postexam_seg1.npy', '125C_5min_Sub1_postexam_seg2.npy', '150C_15min_Sub4_Dev1_seg1.npy', '150C_15min_Sub4_Dev1_seg2.npy', '150C_15min_Sub4_Dev7_seg1.npy', '150C_15min_Sub4_Dev7_seg2.npy', '150C_30min_Sub7_Dev3_seg1.npy', '150C_30min_Sub7_Dev3_seg2.npy', '150C_5min_Sub1_Dev7_seg1.npy', '150C_5min_Sub1_Dev7_seg2.npy', '175C_15min_Sub4_Dev2_seg1.npy', '175C_15min_Sub4_Dev2_seg2.npy', '175C_15min_Sub4_Dev3_seg1.npy', '175C_15min_Sub4_Dev3_seg2.npy', '175C_15min_Sub4_Dev7_seg1.npy', '175C_15min_Sub4_Dev7_seg2.npy', '175C_30min_Sub8_Dev6_seg1.npy', '175C_30min_Sub8_Dev6_seg2.npy', '175C_30min_Sub8_Dev8_seg1.npy', '175C_30min_Sub8_Dev8_seg2.npy', '175C_5min_Sub2_Dev1_seg1.npy', '175C_5min_Sub2_Dev1_seg2.npy', '175C_5min_Sub2_Dev3_seg1.npy', '175C_5min_Sub2_Dev3_seg2.npy', '175C_5min_Sub2_postexam_seg1.npy', '175C_5min_Sub2_postexam_seg2.npy', '2018-06-29_P3HT-PCBM_NOANNEAL_S1_D1_seg1.npy', '2018-06-29_P3HT-PCBM_NOANNEAL_S1_D1_seg2.npy', '2018-06-29_P3HT-PCBM_NOANNEAL_S1_D4_seg1.npy', '2018-06-29_P3HT-PCBM_NOANNEAL_S1_D4_seg2.npy', '2018-06-29_P3HT-PCBM_NOANNEAL_S2_D1_seg1.npy', '2018-06-29_P3HT-PCBM_NOANNEAL_S2_D1_seg2.npy', '2018-06-29_P3HT-PCBM_NOANNEAL_S3_D1_seg1.npy', '2018-06-29_P3HT-PCBM_NOANNEAL_S3_D1_seg2.npy']\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "substring not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-dbab0502f625>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mtemp_stop_indx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'C'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0manl_temp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtemp_stop_indx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: substring not found"
     ]
    }
   ],
   "source": [
    "im_directory = '/Volumes/Tatum_SSD-1/Grad_School/m2py/Morphology_labels/OPV_morph_maps/3_component/'\n",
    "\n",
    "im_filepaths = os.listdir(im_directory)\n",
    "# print (im_filepaths)\n",
    "\n",
    "files = []\n",
    "\n",
    "for fl in im_filepaths:\n",
    "    if fl[-1] == 'v':\n",
    "        pass\n",
    "    elif fl[-1] == 'e':\n",
    "        pass\n",
    "    else:\n",
    "        files.append(fl)\n",
    "        \n",
    "print (files)\n",
    "\n",
    "\n",
    "image_dict = {} # Hold all the image-like data\n",
    "im_labels = {} # Gather all the processing conditions to be the predicted feature\n",
    "\n",
    "for i,fl in enumerate(files):\n",
    "    \n",
    "    if fl[:-6] == files[i+1][:-6]:\n",
    "        seg1 = np.load(im_directory+fl)\n",
    "        seg2 = np.load(im_directory+files[i+1])\n",
    "        \n",
    "        sample = np.stack([seg1, seg1], axis = -1)\n",
    "        \n",
    "        print(sample.shape)\n",
    "        \n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    image_dict[i] = sample\n",
    "    \n",
    "    anl_temp = 0\n",
    "    anl_time = 0\n",
    "    \n",
    "    if 'NOANNEAL' in fl:\n",
    "        pass\n",
    "    \n",
    "    else:\n",
    "        temp_stop_indx = fl.index('C')\n",
    "        anl_temp = int(fl[:temp_stop_indx])\n",
    "\n",
    "\n",
    "        time_start_indx = temp_stop_indx+2\n",
    "        time_stop_indx = fl.index('m')\n",
    "        time_stop_indx = time_stop_indx\n",
    "        anl_time = fl[time_start_indx:time_stop_indx]\n",
    "        anl_time = int(anl_time)\n",
    "        \n",
    "    im_labels[i] = [anl_temp, anl_time]\n",
    "    \n",
    "im_labels_df = pd.fromDict(im_labels)\n",
    "    \n",
    "print (image_dict.shape)\n",
    "im_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_im = image_dict #input features used to make prediction\n",
    "Y_im = im_labels_df #target features to be predicted\n",
    "\n",
    "x_im_train, x_im_test, y_im_train, y_im_test = train_test_split(X_im,Y_im, test_size = 0.2, shuffle = True) #split dataset into separate testing and training datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper parameters\n",
    "num_epochs = 10\n",
    "im_batch_size = int(len(x_train[0])*0.9) # 90% of x_train samples\n",
    "df_batch_size = int(len(x_train[0])*0.9) # 90% of x_train samples\n",
    "im_learning_rate = 0.008\n",
    "df_learning_rate = 0.001\n",
    "\n",
    "# Device configuration (GPU if available, otherwise CPU)\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_im_train_tensor = torch.tensor(x_im_train.values.astype(np.float32)) #convert pd.DataFrame -> np.ndarray -> torch.tensor\n",
    "y_im_train_tensor = torch.tensor(y_im_train.values.astype(np.float32))\n",
    "im_train_tensor = torch.utils.data.TensorDataset(x_im_train_tensor, y_im_train_tensor) #create tensor with features and targets\n",
    "im_training_data_set = torch.utils.data.DataLoader(dataset = im_train_tensor, batch_size = im_batch_size, shuffle = True) #create iterable dataset with batches\n",
    "\n",
    "x_im_test_tensor = torch.tensor(x_im_test.values.astype(np.float32))\n",
    "y_im_test_tensor = torch.tensor(yv_test.values.astype(np.float32))\n",
    "im_test_tensor = torch.utils.data.TensorDataset(x_im_test_tensor, y_im_test_tensor)\n",
    "im_testing_data_set = torch.utils.data.DataLoader(dataset = im_test_tensor, batch_size = im_batch_size, shuffle = True)\n",
    "\n",
    "\n",
    "im_x, im_y, im_z = x_im[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImBranchNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, im_x, im_y, im_z):\n",
    "        super(ImBranchNN, self).__init__()\n",
    "        \n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2D(im_z, 32, kernal_size = 8, stride = 1, padding = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2D(kernal_size = 2, stride = 2)\n",
    "        )\n",
    "        \n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2D(32, 64, kernal_size = 5, stride = 1, padding = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2D(kernal_size = 2, stride = 2)\n",
    "        )\n",
    "            \n",
    "            \n",
    "        fc_nodes = (im_x/4) * (im_y/4) * 64 # 4 because there were 2 maxpool layers with 2x2 Kernals,\n",
    "                                            # reducing the overall channel width & height by half each time\n",
    "        \n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.dropout(),               #helps avoid over-fitting\n",
    "            nn.Linear(fc_nodes, 10000), #Final kernal-size * im_x * im_y\n",
    "            nn.Linear(10000, 5000),\n",
    "            nn.Linear(5000, 1000),\n",
    "            nn.Linear(1000, 100)\n",
    "        )\n",
    "        \n",
    "        self.out_layer = nn.Linear(100, 2) #predicting anneal time and temp\n",
    "            \n",
    "    def forward(self, x_im):\n",
    "        im_out = self.layer1(x_im)\n",
    "        im_out = self.layer2(im_out)\n",
    "        im_out = self.layer3(im_out)\n",
    "        im_train_out = self.out_layer(im_out)\n",
    "        \n",
    "        return im_out, im_train_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_im_branch_one_epoch(model, im_training_data_set, im_criterion):\n",
    "    total_step = len(im_training_data_set)\n",
    "    loss_list = []\n",
    "    \n",
    "    model.train()\n",
    "\n",
    "    for images, labels in im_training_data_set:\n",
    "        # Run the forward pass\n",
    "        im_out, im_train_out = model(images)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=im_learning_rate)\n",
    "        \n",
    "        # Gather the loss\n",
    "        loss = im_criterion(outputs, labels)\n",
    "        loss_list.append(loss.item())\n",
    "\n",
    "        # backprop and perform Adam optimization\n",
    "        torch.autograd.backward(loss)\n",
    "        optimizer.step()\n",
    "    \n",
    "    total = len(loss_list)\n",
    "    epoch_loss = sum(loss_list)/total\n",
    "    \n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, testing_data_set, criterion, optimizer):\n",
    "    #evaluate the model\n",
    "    model.eval()\n",
    "\n",
    "    #don't update nodes during evaluation b/c not training\n",
    "    with torch.no_grad():\n",
    "        test_losses = []\n",
    "        test_total = 0\n",
    "\n",
    "        for inputs, labels in testing_data_set:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "    \n",
    "            # calculate loss per batch of testing data\n",
    "            test_loss = criterion(outputs, labels)\n",
    "            test_losses.append(test_loss.item())\n",
    "            test_total += 1\n",
    "\n",
    "        total_test_loss = sum(test_losses)/test_total\n",
    "\n",
    "        print (f\"Total testing loss is: {total_test_loss}\")\n",
    "    return total_test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_branch_model = ImBranchNN(im_x, im_y, im_z)\n",
    "\n",
    "#define the loss function and the optimizer\n",
    "im_criterion = nn.CrossEntropyLoss()\n",
    "im_optimizer = torch.optim.Adam(model.parameters(), lr = im_learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_train_epoch_losses = []\n",
    "im_test_epoch_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    # First Train the image branch\n",
    "    im_train_epoch_loss = train_im_branch_one_epoch(model = im_branch_model,\n",
    "                                   training_data_set = im_training_data_set,\n",
    "                                   criterion = im_criterion,\n",
    "                                   optimizer = im_optimizer)\n",
    "    \n",
    "    im_train_epoch_losses.append(im_train_epoch_loss)\n",
    "    \n",
    "    im_test_epoch_loss = eval_im_branch(model = im_branch_model,\n",
    "                                 testing_data_set = im_testing_data_set,\n",
    "                                 criterion = im_criterion,\n",
    "                                 optimizer = im_optimizer)\n",
    "    \n",
    "    im_test_epoch_losses.append(im_test_epoch_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (8,6))\n",
    "\n",
    "epochs = np.arange(1, (num_epochs+1), 1)\n",
    "\n",
    "plt.plot(epochs, im_train_epoch_losses, c = 'k', label = 'training error')\n",
    "plt.plot(epochs, im_test_epoch_losses, c = 'r', label = 'testing error')\n",
    "plt.legend(loc = 'upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
