{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72\n",
      "['100C_15min_Sub4_Dev2_seg1.npy', '100C_15min_Sub4_Dev2_seg2.npy', '100C_15min_Sub4_Dev4_seg1.npy', '100C_15min_Sub4_Dev4_seg2.npy', '100C_15min_Sub4_Dev7_seg1.npy', '100C_15min_Sub4_Dev7_seg2.npy', '100C_30min_Sub7_Dev2_seg1.npy', '100C_30min_Sub7_Dev2_seg2.npy', '100C_30min_Sub7_Dev4_seg1.npy', '100C_30min_Sub7_Dev4_seg2.npy', '100C_30min_Sub7_Dev7_seg1.npy', '100C_30min_Sub7_Dev7_seg2.npy', '100C_5min_Sub1_Dev3_seg1.npy', '100C_5min_Sub1_Dev3_seg2.npy', '100C_5min_Sub1_Dev4_90D_seg1.npy', '100C_5min_Sub1_Dev4_90D_seg2.npy', '100C_5min_Sub1_Dev4_seg1.npy', '100C_5min_Sub1_Dev4_seg2.npy', '125C_15min_Sub4_Dev1_seg1.npy', '125C_15min_Sub4_Dev1_seg2.npy', '125C_15min_Sub4_Dev2_seg1.npy', '125C_15min_Sub4_Dev2_seg2.npy', '125C_15min_Sub4_Dev6_seg1.npy', '125C_15min_Sub4_Dev6_seg2.npy', '125C_15min_Sub4_Dev7_seg1.npy', '125C_15min_Sub4_Dev7_seg2.npy', '125C_15min_Sub4_postexam_seg1.npy', '125C_15min_Sub4_postexam_seg2.npy', '125C_30min_Sub8_Dev3_seg1.npy', '125C_30min_Sub8_Dev3_seg2.npy', '125C_30min_Sub8_postexam_seg1.npy', '125C_30min_Sub8_postexam_seg2.npy', '125C_5min_Sub1_Dev2_seg1.npy', '125C_5min_Sub1_Dev2_seg2.npy', '125C_5min_Sub1_Dev3_seg1.npy', '125C_5min_Sub1_Dev3_seg2.npy', '125C_5min_Sub1_Dev6_seg1.npy', '125C_5min_Sub1_Dev6_seg2.npy', '125C_5min_Sub1_postexam_seg1.npy', '125C_5min_Sub1_postexam_seg2.npy', '150C_15min_Sub4_Dev1_seg1.npy', '150C_15min_Sub4_Dev1_seg2.npy', '150C_15min_Sub4_Dev7_seg1.npy', '150C_15min_Sub4_Dev7_seg2.npy', '150C_30min_Sub7_Dev3_seg1.npy', '150C_30min_Sub7_Dev3_seg2.npy', '150C_5min_Sub1_Dev7_seg1.npy', '150C_5min_Sub1_Dev7_seg2.npy', '175C_15min_Sub4_Dev2_seg1.npy', '175C_15min_Sub4_Dev2_seg2.npy', '175C_15min_Sub4_Dev3_seg1.npy', '175C_15min_Sub4_Dev3_seg2.npy', '175C_15min_Sub4_Dev7_seg1.npy', '175C_15min_Sub4_Dev7_seg2.npy', '175C_30min_Sub8_Dev6_seg1.npy', '175C_30min_Sub8_Dev6_seg2.npy', '175C_30min_Sub8_Dev8_seg1.npy', '175C_30min_Sub8_Dev8_seg2.npy', '175C_5min_Sub2_Dev1_seg1.npy', '175C_5min_Sub2_Dev1_seg2.npy', '175C_5min_Sub2_Dev3_seg1.npy', '175C_5min_Sub2_Dev3_seg2.npy', '175C_5min_Sub2_postexam_seg1.npy', '175C_5min_Sub2_postexam_seg2.npy', '2018-06-29_P3HT-PCBM_NOANNEAL_S1_D1_seg1.npy', '2018-06-29_P3HT-PCBM_NOANNEAL_S1_D1_seg2.npy', '2018-06-29_P3HT-PCBM_NOANNEAL_S1_D4_seg1.npy', '2018-06-29_P3HT-PCBM_NOANNEAL_S1_D4_seg2.npy', '2018-06-29_P3HT-PCBM_NOANNEAL_S2_D1_seg1.npy', '2018-06-29_P3HT-PCBM_NOANNEAL_S2_D1_seg2.npy', '2018-06-29_P3HT-PCBM_NOANNEAL_S3_D1_seg1.npy', '2018-06-29_P3HT-PCBM_NOANNEAL_S3_D1_seg2.npy']\n"
     ]
    }
   ],
   "source": [
    "im_directory = '/Volumes/Tatum_SSD-1/Grad_School/m2py/Morphology_labels/OPV_morph_maps/3_component/'\n",
    "\n",
    "im_filepaths = os.listdir(im_directory)\n",
    "# print (im_filepaths)\n",
    "\n",
    "files = []\n",
    "\n",
    "for fl in im_filepaths:\n",
    "    if fl[-1] == 'v':\n",
    "        pass\n",
    "    elif fl[-1] == 'e':\n",
    "        pass\n",
    "    else:\n",
    "        files.append(fl)\n",
    "        \n",
    "print (len(files))\n",
    "print (files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n",
      "(256, 256, 2)\n",
      "(36, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>100</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>100</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0   1\n",
       "0  100  15\n",
       "2  100  15\n",
       "4  100  15\n",
       "6  100  30\n",
       "8  100  30"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_dict = {} # Hold all the image-like data\n",
    "im_labels = {} # Gather all the processing conditions to be the predicted feature\n",
    "\n",
    "for i,fl in enumerate(files):\n",
    "    \n",
    "    anl_temp = 0\n",
    "    anl_time = 0\n",
    "    \n",
    "    if i < len(files)-1:\n",
    "        if fl[:-6] == files[i+1][:-6]:\n",
    "            seg1 = np.load(im_directory+fl)\n",
    "            seg2 = np.load(im_directory+files[i+1])\n",
    "            sample = np.stack([seg1, seg2], axis = -1)\n",
    "            sample = sample.astype(np.double)\n",
    "#             print (sample.dtype)\n",
    "            \n",
    "            im_index = len(image_dict)\n",
    "            \n",
    "            image_dict[im_index] = sample\n",
    "            \n",
    "            if 'NOANNEAL' in fl:\n",
    "                im_labels[i] = [anl_temp, anl_time]\n",
    "\n",
    "            else:\n",
    "                temp_stop_indx = fl.index('C')\n",
    "                anl_temp = int(fl[:temp_stop_indx])\n",
    "                \n",
    "                time_start_indx = temp_stop_indx+2\n",
    "                time_stop_indx = fl.index('m')\n",
    "                time_stop_indx = time_stop_indx\n",
    "                anl_time = fl[time_start_indx:time_stop_indx]\n",
    "                anl_time = int(anl_time)\n",
    "\n",
    "                im_labels[i] = [anl_temp, anl_time]\n",
    "\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "im_labels_df = pd.DataFrame.from_dict(im_labels, orient = 'index')\n",
    "    \n",
    "print (len(image_dict))\n",
    "print (image_dict[0].shape)\n",
    "print (im_labels_df.shape)\n",
    "im_labels_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_im = image_dict #input features used to make prediction\n",
    "Y_im = im_labels_df #target features to be predicted\n",
    "\n",
    "x_im_train, x_im_test, y_im_train, y_im_test = train_test_split(X_im,Y_im, test_size = 0.2, shuffle = True) #split dataset into separate testing and training datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper parameters\n",
    "num_epochs = 10\n",
    "im_batch_size = int(len(x_im_train[0])*0.9) # 90% of x_train samples\n",
    "im_learning_rate = 0.008\n",
    "\n",
    "# Device configuration (GPU if available, otherwise CPU)\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_im_train_tensor = torch.tensor(x_im_train).float() #for conv2d, inputs need to be doubles\n",
    "y_im_train_tensor = torch.tensor(y_im_train.values.astype(np.float32)).float()#convert pd.DataFrame -> np.ndarray -> torch.tensor\n",
    "x_im_train_tensor = x_im_train_tensor.view(28, 2, 256, 256) #convert tensor of size [28, 256, 256, 2] to [28, 2, 256, 256] to fit Conv2D parameters\n",
    "im_train_tensor = torch.utils.data.TensorDataset(x_im_train_tensor, y_im_train_tensor) #create tensor with features and targets\n",
    "im_training_data_set = torch.utils.data.DataLoader(dataset = im_train_tensor, batch_size = im_batch_size, shuffle = True) #create iterable dataset with batches\n",
    "\n",
    "x_im_test_tensor = torch.tensor(x_im_test).float()\n",
    "y_im_test_tensor = torch.tensor(y_im_test.values.astype(np.float32)).float()\n",
    "x_im_test_tensor = x_im_test_tensor.view(8, 2, 256, 256) #convert tensor of size [8, 256, 256, 2] to [8, 2, 256, 256] to fit Conv2D parameters\n",
    "im_test_tensor = torch.utils.data.TensorDataset(x_im_test_tensor, y_im_test_tensor)\n",
    "im_testing_data_set = torch.utils.data.DataLoader(dataset = im_test_tensor, batch_size = im_batch_size, shuffle = True)\n",
    "\n",
    "\n",
    "im_x, im_y, im_z = X_im[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImBranchNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, im_x, im_y, im_z):\n",
    "        super(ImBranchNN, self).__init__()\n",
    "        \n",
    "#         fc_nodes = int((im_x/4) * (im_y/4) * 64) # 4 because there were 2 maxpool layers with 2x2 Kernals,\n",
    "                                                 # reducing the overall channel width & height by half each time\n",
    "        \n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(im_z, 32, kernel_size = 8, stride = 1, padding = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "        )\n",
    "        \n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size = 5, stride = 1, padding = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "        )\n",
    "        \n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Dropout(),               #helps avoid over-fitting\n",
    "            nn.Linear(109312, 10000),\n",
    "            nn.Linear(10000, 5000),\n",
    "            nn.Linear(5000, 1000),\n",
    "            nn.Linear(1000, 100)\n",
    "        )\n",
    "        \n",
    "        self.out_layer = nn.Linear(100, 2) #predicting anneal time and temp\n",
    "            \n",
    "    def forward(self, x_im):\n",
    "        im_out = self.layer1(x_im)\n",
    "        im_out = self.layer2(im_out)\n",
    "        \n",
    "        im_out = im_out.view(-1,1) #reshape output for linear layers\n",
    "        \n",
    "        im_out = self.layer3(im_out)\n",
    "        im_train_out = self.out_layer(im_out)\n",
    "        \n",
    "        return im_out, im_train_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_im_branch_one_epoch(model, training_data_set, criterion, optimizer):\n",
    "    total_step = len(im_training_data_set)\n",
    "    loss_list = []\n",
    "    \n",
    "    model.train()\n",
    "\n",
    "    for images, labels in im_training_data_set:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Run the forward pass\n",
    "        im_out, im_train_out = model(images)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=im_learning_rate)\n",
    "        \n",
    "        # Gather the loss\n",
    "        loss = im_criterion(outputs, labels)\n",
    "        loss_list.append(loss.item())\n",
    "\n",
    "        # backprop and perform Adam optimization\n",
    "        torch.autograd.backward(loss)\n",
    "        optimizer.step()\n",
    "    \n",
    "    total = len(loss_list)\n",
    "    epoch_loss = sum(loss_list)/total\n",
    "    \n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, testing_data_set, criterion):\n",
    "    #evaluate the model\n",
    "    model.eval()\n",
    "\n",
    "    #don't update nodes during evaluation b/c not training\n",
    "    with torch.no_grad():\n",
    "        test_losses = []\n",
    "        test_total = 0\n",
    "\n",
    "        for inputs, labels in testing_data_set:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "    \n",
    "            # calculate loss per batch of testing data\n",
    "            test_loss = criterion(outputs, labels)\n",
    "            test_losses.append(test_loss.item())\n",
    "            test_total += 1\n",
    "\n",
    "        total_test_loss = sum(test_losses)/test_total\n",
    "\n",
    "        print (f\"Total testing loss is: {total_test_loss}\")\n",
    "    return total_test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_branch_model = ImBranchNN(im_x, im_y, im_z)\n",
    "\n",
    "#define the loss function and the optimizer\n",
    "im_criterion = nn.CrossEntropyLoss()\n",
    "im_optimizer = torch.optim.Adam(im_branch_model.parameters(), lr = im_learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "size mismatch, m1: [6668032 x 1], m2: [109312 x 10000] at /Users/distiller/project/conda/conda-bld/pytorch_1579022061893/work/aten/src/TH/generic/THTensorMath.cpp:136",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-a89827d1eca2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m                                    \u001b[0mtraining_data_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mim_training_data_set\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                                    \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mim_criterion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m                                    optimizer = im_optimizer)\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mim_train_epoch_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim_train_epoch_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-54b78f3f3c74>\u001b[0m in \u001b[0;36mtrain_im_branch_one_epoch\u001b[0;34m(model, training_data_set, criterion, optimizer)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;31m# Run the forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mim_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mim_train_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-0e5663c8cec6>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x_im)\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mim_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mim_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#reshape output for linear layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mim_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0mim_train_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1368\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1370\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1371\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: size mismatch, m1: [6668032 x 1], m2: [109312 x 10000] at /Users/distiller/project/conda/conda-bld/pytorch_1579022061893/work/aten/src/TH/generic/THTensorMath.cpp:136"
     ]
    }
   ],
   "source": [
    "im_train_epoch_losses = []\n",
    "im_test_epoch_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    # First Train the image branch\n",
    "    im_train_epoch_loss = train_im_branch_one_epoch(model = im_branch_model,\n",
    "                                   training_data_set = im_training_data_set,\n",
    "                                   criterion = im_criterion,\n",
    "                                   optimizer = im_optimizer)\n",
    "    \n",
    "    im_train_epoch_losses.append(im_train_epoch_loss)\n",
    "    \n",
    "    im_test_epoch_loss = eval_im_branch(model = im_branch_model,\n",
    "                                 testing_data_set = im_testing_data_set,\n",
    "                                 criterion = im_criterion)\n",
    "    \n",
    "    im_test_epoch_losses.append(im_test_epoch_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (8,6))\n",
    "\n",
    "epochs = np.arange(1, (num_epochs+1), 1)\n",
    "\n",
    "plt.plot(epochs, im_train_epoch_losses, c = 'k', label = 'training error')\n",
    "plt.plot(epochs, im_test_epoch_losses, c = 'r', label = 'testing error')\n",
    "plt.legend(loc = 'upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
